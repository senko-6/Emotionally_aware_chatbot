{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.12.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":31260,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install -q transformers datasets peft accelerate bitsandbytes evaluate huggingface_hub","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-20T15:59:07.786634Z","iopub.execute_input":"2026-01-20T15:59:07.786916Z","iopub.status.idle":"2026-01-20T15:59:14.861209Z","shell.execute_reply.started":"2026-01-20T15:59:07.786891Z","shell.execute_reply":"2026-01-20T15:59:14.860223Z"}},"outputs":[{"name":"stdout","text":"\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m59.1/59.1 MB\u001b[0m \u001b[31m32.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m84.1/84.1 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"from huggingface_hub import login\nimport os\nos.environ[\"HF_TOKEN\"] = \"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\"\n\nlogin(token=os.environ[\"HF_TOKEN\"])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-20T16:07:25.053317Z","iopub.execute_input":"2026-01-20T16:07:25.053675Z","iopub.status.idle":"2026-01-20T16:07:25.098798Z","shell.execute_reply.started":"2026-01-20T16:07:25.053646Z","shell.execute_reply":"2026-01-20T16:07:25.098088Z"}},"outputs":[{"name":"stderr","text":"Note: Environment variable`HF_TOKEN` is set and is the current active token independently from the token you've just configured.\nWARNING:huggingface_hub._login:Note: Environment variable`HF_TOKEN` is set and is the current active token independently from the token you've just configured.\n","output_type":"stream"}],"execution_count":30},{"cell_type":"code","source":"import torch\nimport numpy as np\nfrom datasets import load_dataset\nfrom transformers import (\n    RobertaTokenizer,\n    RobertaForSequenceClassification,\n    TrainingArguments,\n    Trainer,\n    DataCollatorWithPadding\n)\nfrom peft import LoraConfig, get_peft_model, TaskType\nimport evaluate ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-20T16:07:55.053827Z","iopub.execute_input":"2026-01-20T16:07:55.054376Z","iopub.status.idle":"2026-01-20T16:07:55.058597Z","shell.execute_reply.started":"2026-01-20T16:07:55.054344Z","shell.execute_reply":"2026-01-20T16:07:55.057857Z"}},"outputs":[],"execution_count":31},{"cell_type":"code","source":"dataset = load_dataset(\"go_emotions\")\nprint(dataset)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-20T16:07:55.060285Z","iopub.execute_input":"2026-01-20T16:07:55.060682Z","iopub.status.idle":"2026-01-20T16:07:55.788951Z","shell.execute_reply.started":"2026-01-20T16:07:55.060648Z","shell.execute_reply":"2026-01-20T16:07:55.788340Z"}},"outputs":[{"name":"stdout","text":"DatasetDict({\n    train: Dataset({\n        features: ['text', 'labels', 'id'],\n        num_rows: 43410\n    })\n    validation: Dataset({\n        features: ['text', 'labels', 'id'],\n        num_rows: 5426\n    })\n    test: Dataset({\n        features: ['text', 'labels', 'id'],\n        num_rows: 5427\n    })\n})\n","output_type":"stream"}],"execution_count":32},{"cell_type":"code","source":"ekman_mapping = {\n    \"anger\" : [\"anger\", \"annoyance\", \"disapproval\"],\n    \"disgust\" : [\"disgust\"],\n    \"fear\" : [\"fear\", \"nervousness\"],\n    \"joy\" : [\"joy\", \"amuzement\", \"approval\", \"admiration\", \"gratitude\", \"love\", \"optimism\", \"pride\", \"relief\", \"excitement\", \"caring\"],\n    \"sadness\" : [\"sadness\", \"disappointment\", \"embarrassment\", \"grief\", \"remorse\"],\n    \"surprise\" : [\"surprise\", \"confusion\", \"suriosity\", \"realization\"],\n    \"neutral\" : [\"neutral\"]\n}","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-20T16:07:55.789772Z","iopub.execute_input":"2026-01-20T16:07:55.790042Z","iopub.status.idle":"2026-01-20T16:07:55.794100Z","shell.execute_reply.started":"2026-01-20T16:07:55.790019Z","shell.execute_reply":"2026-01-20T16:07:55.793562Z"}},"outputs":[],"execution_count":33},{"cell_type":"code","source":"label_names = dataset[\"train\"].features[\"labels\"].feature.names\n\nekman_labels = list(ekman_mapping.keys())\nekman2id = {k: i for i, k in enumerate(ekman_labels)}\n\nlabel_to_ekman = {}\nfor ekman, emotions in ekman_mapping.items():\n    for e in emotions:\n        label_to_ekman[e] = ekman2id[ekman]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-20T16:07:55.795016Z","iopub.execute_input":"2026-01-20T16:07:55.795244Z","iopub.status.idle":"2026-01-20T16:07:55.809911Z","shell.execute_reply.started":"2026-01-20T16:07:55.795223Z","shell.execute_reply":"2026-01-20T16:07:55.809244Z"}},"outputs":[],"execution_count":34},{"cell_type":"code","source":"def map_to_ekman(example):\n    labels = example[\"labels\"]\n    if len(labels) == 0:\n        example[\"ekman_labels\"] = ekman2id[\"neutral\"]\n        return example\n\n    primary_label = label_names[labels[0]]\n    example[\"ekman_label\"] = label_to_ekman.get(primary_label, ekman2id[\"neutral\"])\n    return example","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-20T16:07:55.811440Z","iopub.execute_input":"2026-01-20T16:07:55.811984Z","iopub.status.idle":"2026-01-20T16:07:55.823434Z","shell.execute_reply.started":"2026-01-20T16:07:55.811961Z","shell.execute_reply":"2026-01-20T16:07:55.822806Z"}},"outputs":[],"execution_count":35},{"cell_type":"code","source":"dataset = dataset.map(map_to_ekman)\ndataset = dataset.remove_columns([\"labels\", \"id\"])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-20T16:07:55.824435Z","iopub.execute_input":"2026-01-20T16:07:55.824729Z","iopub.status.idle":"2026-01-20T16:07:55.849837Z","shell.execute_reply.started":"2026-01-20T16:07:55.824697Z","shell.execute_reply":"2026-01-20T16:07:55.849239Z"}},"outputs":[],"execution_count":36},{"cell_type":"raw","source":"","metadata":{"execution":{"iopub.status.busy":"2026-01-17T08:02:05.755779Z","iopub.execute_input":"2026-01-17T08:02:05.756084Z","iopub.status.idle":"2026-01-17T08:02:05.777391Z","shell.execute_reply.started":"2026-01-17T08:02:05.756059Z","shell.execute_reply":"2026-01-17T08:02:05.776813Z"}}},{"cell_type":"code","source":"dataset = dataset[\"train\"].train_test_split(test_size=0.1, seed=42)\ntrain_ds = dataset[\"train\"]\neval_ds = dataset[\"test\"]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-20T16:07:55.850633Z","iopub.execute_input":"2026-01-20T16:07:55.850809Z","iopub.status.idle":"2026-01-20T16:07:55.857990Z","shell.execute_reply.started":"2026-01-20T16:07:55.850790Z","shell.execute_reply":"2026-01-20T16:07:55.857426Z"}},"outputs":[],"execution_count":37},{"cell_type":"code","source":"tokenizer = RobertaTokenizer.from_pretrained(\"roberta-base\")\n\ndef tokenize(batch):\n    return tokenizer(batch[\"text\"], truncation = True, max_length = 128)\n\ntrain_ds = train_ds.map(tokenize, batched=True)\neval_ds = eval_ds.map(tokenize, batched=True)\n\ntrain_ds = train_ds.rename_column(\"ekman_label\", \"labels\")\neval_ds = eval_ds.rename_column(\"ekman_label\", \"labels\")\n\ntrain_ds.set_format(\"torch\")\neval_ds.set_format(\"torch\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-20T16:07:55.858864Z","iopub.execute_input":"2026-01-20T16:07:55.859216Z","iopub.status.idle":"2026-01-20T16:07:57.654610Z","shell.execute_reply.started":"2026-01-20T16:07:55.859181Z","shell.execute_reply":"2026-01-20T16:07:57.654036Z"}},"outputs":[],"execution_count":38},{"cell_type":"code","source":"model = RobertaForSequenceClassification.from_pretrained(\"roberta-base\", num_labels = 7)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-20T16:07:57.655490Z","iopub.execute_input":"2026-01-20T16:07:57.655789Z","iopub.status.idle":"2026-01-20T16:07:57.814237Z","shell.execute_reply.started":"2026-01-20T16:07:57.655758Z","shell.execute_reply":"2026-01-20T16:07:57.813664Z"}},"outputs":[{"name":"stderr","text":"Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"}],"execution_count":39},{"cell_type":"code","source":"lora_config = LoraConfig(\n    task_type=TaskType.SEQ_CLS,\n    r=8,\n    lora_alpha=32,\n    lora_dropout=0.1,\n    target_modules=[\"query\", \"value\"]\n)\n\nmodel = get_peft_model(model, lora_config)\nmodel.print_trainable_parameters()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-20T16:07:57.815028Z","iopub.execute_input":"2026-01-20T16:07:57.815290Z","iopub.status.idle":"2026-01-20T16:07:57.851054Z","shell.execute_reply.started":"2026-01-20T16:07:57.815267Z","shell.execute_reply":"2026-01-20T16:07:57.850494Z"}},"outputs":[{"name":"stdout","text":"trainable params: 890,887 || all params: 125,541,902 || trainable%: 0.7096\n","output_type":"stream"}],"execution_count":40},{"cell_type":"code","source":"accuracy = evaluate.load(\"accuracy\")\n\ndef compute_metrics(eval_pred):\n    logits, labels = eval_pred\n    preds = np.argmax(logits, axis = 1)\n    return accuracy.compute(predictions=preds, references=labels)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-20T16:07:57.851817Z","iopub.execute_input":"2026-01-20T16:07:57.852001Z","iopub.status.idle":"2026-01-20T16:07:58.385210Z","shell.execute_reply.started":"2026-01-20T16:07:57.851981Z","shell.execute_reply":"2026-01-20T16:07:58.384478Z"}},"outputs":[],"execution_count":41},{"cell_type":"code","source":"training_args = TrainingArguments(\n    output_dir=\"./ekman_roberta_lora\",\n    eval_strategy=\"steps\",\n    per_device_train_batch_size=32,\n    per_device_eval_batch_size=32,\n    gradient_accumulation_steps=2,\n    learning_rate=2e-4,\n    num_train_epochs=3,\n    fp16=True,\n    logging_steps=100,\n    eval_steps=500,\n    save_steps=500,\n    save_total_limit=2,\n    report_to=\"none\"\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-20T16:07:58.386097Z","iopub.execute_input":"2026-01-20T16:07:58.386405Z","iopub.status.idle":"2026-01-20T16:07:58.414876Z","shell.execute_reply.started":"2026-01-20T16:07:58.386380Z","shell.execute_reply":"2026-01-20T16:07:58.414150Z"}},"outputs":[],"execution_count":42},{"cell_type":"code","source":"trainer = Trainer(\n    model = model,\n    args = training_args,\n    train_dataset = train_ds,\n    eval_dataset = eval_ds,\n    tokenizer = tokenizer,\n    data_collator = DataCollatorWithPadding(tokenizer),\n    compute_metrics=compute_metrics\n)\ntrainer.train()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-20T16:07:58.415830Z","iopub.execute_input":"2026-01-20T16:07:58.416084Z","iopub.status.idle":"2026-01-20T16:13:37.531676Z","shell.execute_reply.started":"2026-01-20T16:07:58.416053Z","shell.execute_reply":"2026-01-20T16:13:37.530963Z"}},"outputs":[{"name":"stderr","text":"/tmp/ipykernel_55/1029857968.py:1: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n  trainer = Trainer(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='1833' max='1833' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [1833/1833 05:38, Epoch 3/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Accuracy</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>500</td>\n      <td>0.925000</td>\n      <td>0.867796</td>\n      <td>0.669431</td>\n    </tr>\n    <tr>\n      <td>1000</td>\n      <td>0.866200</td>\n      <td>0.856790</td>\n      <td>0.668279</td>\n    </tr>\n    <tr>\n      <td>1500</td>\n      <td>0.842000</td>\n      <td>0.855389</td>\n      <td>0.667127</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"execution_count":43,"output_type":"execute_result","data":{"text/plain":"TrainOutput(global_step=1833, training_loss=0.9042207621123318, metrics={'train_runtime': 338.3027, 'train_samples_per_second': 346.456, 'train_steps_per_second': 5.418, 'total_flos': 2194428061274652.0, 'train_loss': 0.9042207621123318, 'epoch': 3.0})"},"metadata":{}}],"execution_count":43},{"cell_type":"code","source":"trainer.evaluate()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-20T16:13:37.534943Z","iopub.execute_input":"2026-01-20T16:13:37.535274Z","iopub.status.idle":"2026-01-20T16:13:43.334660Z","shell.execute_reply.started":"2026-01-20T16:13:37.535247Z","shell.execute_reply":"2026-01-20T16:13:43.333968Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"execution_count":44,"output_type":"execute_result","data":{"text/plain":"{'eval_loss': 0.8501855134963989,\n 'eval_accuracy': 0.6715042616908546,\n 'eval_runtime': 5.7896,\n 'eval_samples_per_second': 749.797,\n 'eval_steps_per_second': 23.491,\n 'epoch': 3.0}"},"metadata":{}}],"execution_count":44},{"cell_type":"code","source":"from sklearn.metrics import classification_report\n\npreds = trainer.predict(eval_ds)\ny_pred = preds.predictions.argmax(axis=1)\ny_true = preds.label_ids\n\nprint(classification_report(\n    y_true,\n    y_pred,\n    target_names=ekman_labels\n))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-20T16:13:43.335625Z","iopub.execute_input":"2026-01-20T16:13:43.335847Z","iopub.status.idle":"2026-01-20T16:13:49.320709Z","shell.execute_reply.started":"2026-01-20T16:13:43.335825Z","shell.execute_reply":"2026-01-20T16:13:49.319796Z"}},"outputs":[{"name":"stdout","text":"              precision    recall  f1-score   support\n\n       anger       0.52      0.56      0.54       542\n     disgust       0.35      0.26      0.30        76\n        fear       0.47      0.57      0.51        60\n         joy       0.75      0.79      0.77      1376\n     sadness       0.61      0.58      0.59       280\n    surprise       0.49      0.35      0.41       251\n     neutral       0.70      0.69      0.70      1756\n\n    accuracy                           0.67      4341\n   macro avg       0.56      0.54      0.55      4341\nweighted avg       0.67      0.67      0.67      4341\n\n","output_type":"stream"}],"execution_count":45},{"cell_type":"code","source":"model.save_pretrained(\"./ekman_roberta_lora\")\ntokenizer.save_pretrained(\"./ekman_roberta_lora\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-20T16:13:49.322055Z","iopub.execute_input":"2026-01-20T16:13:49.322454Z","iopub.status.idle":"2026-01-20T16:13:49.569925Z","shell.execute_reply.started":"2026-01-20T16:13:49.322410Z","shell.execute_reply":"2026-01-20T16:13:49.569018Z"}},"outputs":[{"execution_count":46,"output_type":"execute_result","data":{"text/plain":"('./ekman_roberta_lora/tokenizer_config.json',\n './ekman_roberta_lora/special_tokens_map.json',\n './ekman_roberta_lora/vocab.json',\n './ekman_roberta_lora/merges.txt',\n './ekman_roberta_lora/added_tokens.json')"},"metadata":{}}],"execution_count":46},{"cell_type":"code","source":"import torch\nimport torch.nn.functional as F\nfrom transformers import RobertaTokenizer, RobertaForSequenceClassification","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-20T16:13:49.570945Z","iopub.execute_input":"2026-01-20T16:13:49.571242Z","iopub.status.idle":"2026-01-20T16:13:49.575378Z","shell.execute_reply.started":"2026-01-20T16:13:49.571203Z","shell.execute_reply":"2026-01-20T16:13:49.574610Z"}},"outputs":[],"execution_count":47},{"cell_type":"code","source":"MODEL_PATH = \"./ekman_roberta_lora\"\n\ntokenizer = RobertaTokenizer.from_pretrained(MODEL_PATH)\nmodel = RobertaForSequenceClassification.from_pretrained(MODEL_PATH, num_labels=7)\n\nmodel.eval()\n\nekman_labels = [\n    \"anger\", \"disgust\", \"fear\", \"joy\", \"sadness\", \"surprise\", \"neutral\"\n]\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-20T16:13:49.576406Z","iopub.execute_input":"2026-01-20T16:13:49.576739Z","iopub.status.idle":"2026-01-20T16:13:49.898056Z","shell.execute_reply.started":"2026-01-20T16:13:49.576703Z","shell.execute_reply":"2026-01-20T16:13:49.897375Z"}},"outputs":[{"name":"stderr","text":"Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"}],"execution_count":48},{"cell_type":"code","source":"def predict_emotion(text):\n    inputs = tokenizer(\n        text,\n        return_tensors=\"pt\",\n        truncation=True,\n        max_length=128\n    )\n    with torch.no_grad():\n        outputs = model(**inputs)\n        logits = outputs.logits\n        probs = F.softmax(logits, dim=1)\n    pred_id = torch.argmax(probs, dim=1).item()\n    confidence = probs[0][pred_id].item()\n\n    return {\n        \"text\":text,\n        \"emotion\":ekman_labels[pred_id],\n        \"confidence\":round(confidence, 3),\n        \"probabilities\":{\n            ekman_labels[i]:round(probs[0][i].item(), 3)\n            for i in range(len(ekman_labels))\n        }\n    }","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-20T16:13:49.899064Z","iopub.execute_input":"2026-01-20T16:13:49.899406Z","iopub.status.idle":"2026-01-20T16:13:49.905181Z","shell.execute_reply.started":"2026-01-20T16:13:49.899373Z","shell.execute_reply":"2026-01-20T16:13:49.904556Z"}},"outputs":[],"execution_count":49},{"cell_type":"code","source":"examples = [\n    \"Bro this traffic is insane, I'm already late üò°\",\n    \"I feel kind of empty today, not sure why\",\n    \"That actually made me smile a lot\",\n    \"Wait WHAT?? You never told me this!\",\n    \"I'm worried about tomorrow's interview\",\n    \"Okay cool, noted.\"\n]\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-20T16:13:49.906110Z","iopub.execute_input":"2026-01-20T16:13:49.906423Z","iopub.status.idle":"2026-01-20T16:13:49.923960Z","shell.execute_reply.started":"2026-01-20T16:13:49.906397Z","shell.execute_reply":"2026-01-20T16:13:49.922987Z"}},"outputs":[],"execution_count":50},{"cell_type":"code","source":"for text in examples:\n    result = predict_emotion(text)\n    print(f\"\\nText: {result['text']}\")\n    print(f\"Emotion: {result['emotion']} | confidence: {result['confidence']}\")\n    print(\"Probabilities:\", result[\"probabilities\"])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-20T16:13:49.924902Z","iopub.execute_input":"2026-01-20T16:13:49.925457Z","iopub.status.idle":"2026-01-20T16:13:50.346943Z","shell.execute_reply.started":"2026-01-20T16:13:49.925414Z","shell.execute_reply":"2026-01-20T16:13:50.346128Z"}},"outputs":[{"name":"stdout","text":"\nText: Bro this traffic is insane, I'm already late üò°\nEmotion: anger | confidence: 0.444\nProbabilities: {'anger': 0.444, 'disgust': 0.011, 'fear': 0.022, 'joy': 0.177, 'sadness': 0.067, 'surprise': 0.057, 'neutral': 0.222}\n\nText: I feel kind of empty today, not sure why\nEmotion: surprise | confidence: 0.704\nProbabilities: {'anger': 0.043, 'disgust': 0.001, 'fear': 0.002, 'joy': 0.007, 'sadness': 0.171, 'surprise': 0.704, 'neutral': 0.071}\n\nText: That actually made me smile a lot\nEmotion: joy | confidence: 0.733\nProbabilities: {'anger': 0.001, 'disgust': 0.0, 'fear': 0.0, 'joy': 0.733, 'sadness': 0.003, 'surprise': 0.021, 'neutral': 0.24}\n\nText: Wait WHAT?? You never told me this!\nEmotion: surprise | confidence: 0.501\nProbabilities: {'anger': 0.175, 'disgust': 0.001, 'fear': 0.001, 'joy': 0.009, 'sadness': 0.014, 'surprise': 0.501, 'neutral': 0.299}\n\nText: I'm worried about tomorrow's interview\nEmotion: fear | confidence: 0.932\nProbabilities: {'anger': 0.002, 'disgust': 0.002, 'fear': 0.932, 'joy': 0.025, 'sadness': 0.025, 'surprise': 0.007, 'neutral': 0.006}\n\nText: Okay cool, noted.\nEmotion: joy | confidence: 0.912\nProbabilities: {'anger': 0.007, 'disgust': 0.0, 'fear': 0.0, 'joy': 0.912, 'sadness': 0.0, 'surprise': 0.006, 'neutral': 0.074}\n","output_type":"stream"}],"execution_count":51},{"cell_type":"code","source":"import torch\nfrom peft import PeftModel\nfrom transformers import (RobertaForSequenceClassification, RobertaTokenizer)\n\nBASE_MODEL = \"roberta-base\"\nLORA_PATH = \"./ekman_roberta_lora\"\n\nbase_model = RobertaForSequenceClassification.from_pretrained(BASE_MODEL, num_labels=7)\nmodel = PeftModel.from_pretrained(base_model, LORA_PATH)\ntokenizer = RobertaTokenizer.from_pretrained(LORA_PATH)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-20T16:13:50.348020Z","iopub.execute_input":"2026-01-20T16:13:50.348382Z","iopub.status.idle":"2026-01-20T16:13:50.671636Z","shell.execute_reply.started":"2026-01-20T16:13:50.348344Z","shell.execute_reply":"2026-01-20T16:13:50.670618Z"}},"outputs":[{"name":"stderr","text":"Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"}],"execution_count":52},{"cell_type":"code","source":"merged_model = model.merge_and_unload()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-20T16:13:50.672864Z","iopub.execute_input":"2026-01-20T16:13:50.673646Z","iopub.status.idle":"2026-01-20T16:13:50.812239Z","shell.execute_reply.started":"2026-01-20T16:13:50.673605Z","shell.execute_reply":"2026-01-20T16:13:50.811394Z"}},"outputs":[],"execution_count":53},{"cell_type":"code","source":"SAVE_DIR = \"./feeler\"\nmerged_model.save_pretrained(SAVE_DIR)\ntokenizer.save_pretrained(SAVE_DIR)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-20T16:13:50.813281Z","iopub.execute_input":"2026-01-20T16:13:50.813561Z","iopub.status.idle":"2026-01-20T16:13:51.985397Z","shell.execute_reply.started":"2026-01-20T16:13:50.813499Z","shell.execute_reply":"2026-01-20T16:13:51.984691Z"}},"outputs":[{"execution_count":54,"output_type":"execute_result","data":{"text/plain":"('./feeler/tokenizer_config.json',\n './feeler/special_tokens_map.json',\n './feeler/vocab.json',\n './feeler/merges.txt',\n './feeler/added_tokens.json')"},"metadata":{}}],"execution_count":54},{"cell_type":"code","source":"!ls feeler","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-20T16:13:51.986427Z","iopub.execute_input":"2026-01-20T16:13:51.986785Z","iopub.status.idle":"2026-01-20T16:13:52.181487Z","shell.execute_reply.started":"2026-01-20T16:13:51.986748Z","shell.execute_reply":"2026-01-20T16:13:52.180565Z"}},"outputs":[{"name":"stdout","text":"config.json  model.safetensors\t      tokenizer_config.json\nmerges.txt   special_tokens_map.json  vocab.json\n","output_type":"stream"}],"execution_count":55},{"cell_type":"code","source":"from huggingface_hub import login\nlogin(token=\"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\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-20T16:13:52.183168Z","iopub.execute_input":"2026-01-20T16:13:52.183576Z","iopub.status.idle":"2026-01-20T16:13:52.228265Z","shell.execute_reply.started":"2026-01-20T16:13:52.183502Z","shell.execute_reply":"2026-01-20T16:13:52.227667Z"}},"outputs":[{"name":"stderr","text":"Note: Environment variable`HF_TOKEN` is set and is the current active token independently from the token you've just configured.\nWARNING:huggingface_hub._login:Note: Environment variable`HF_TOKEN` is set and is the current active token independently from the token you've just configured.\n","output_type":"stream"}],"execution_count":56},{"cell_type":"code","source":"from huggingface_hub import whoami\n\nwhoami()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-20T16:13:52.229186Z","iopub.execute_input":"2026-01-20T16:13:52.229460Z","iopub.status.idle":"2026-01-20T16:13:52.271370Z","shell.execute_reply.started":"2026-01-20T16:13:52.229436Z","shell.execute_reply":"2026-01-20T16:13:52.270680Z"}},"outputs":[{"execution_count":57,"output_type":"execute_result","data":{"text/plain":"{'type': 'user',\n 'id': '695fbae7764e2c39f467f114',\n 'name': 'senko3485',\n 'fullname': 'omkar pawar',\n 'email': 'omkarwork3333@gmail.com',\n 'emailVerified': True,\n 'canPay': False,\n 'billingMode': 'prepaid',\n 'periodEnd': 1769904000,\n 'isPro': False,\n 'avatarUrl': '/avatars/f05d2a5bb216e117588537bddb7b8082.svg',\n 'orgs': [],\n 'auth': {'type': 'access_token',\n  'accessToken': {'displayName': 'kaggle_push',\n   'role': 'write',\n   'createdAt': '2026-01-20T14:32:26.294Z'}}}"},"metadata":{}}],"execution_count":57},{"cell_type":"code","source":"username = \"senko3485\"\nrepo_name = \"feeler\"\n\nmerged_model.push_to_hub(f\"{username}/{repo_name}\")\ntokenizer.push_to_hub(f\"{username}/{repo_name}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-20T16:13:52.272346Z","iopub.execute_input":"2026-01-20T16:13:52.272663Z","iopub.status.idle":"2026-01-20T16:14:03.420004Z","shell.execute_reply.started":"2026-01-20T16:13:52.272637Z","shell.execute_reply":"2026-01-20T16:14:03.419345Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Processing Files (0 / 0): |          |  0.00B /  0.00B            ","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bfb6b9765399409c97141be6c01964a8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"New Data Upload: |          |  0.00B /  0.00B            ","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7f0ff76b4d9f415d9be483a4b6e8c109"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"README.md: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e61bdcd620cd4029970448e24fd06295"}},"metadata":{}},{"execution_count":58,"output_type":"execute_result","data":{"text/plain":"CommitInfo(commit_url='https://huggingface.co/senko3485/feeler/commit/e809410fcca59d766cacebc49f585ca3c45a7d65', commit_message='Upload tokenizer', commit_description='', oid='e809410fcca59d766cacebc49f585ca3c45a7d65', pr_url=None, repo_url=RepoUrl('https://huggingface.co/senko3485/feeler', endpoint='https://huggingface.co', repo_type='model', repo_id='senko3485/feeler'), pr_revision=None, pr_num=None)"},"metadata":{}}],"execution_count":58},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}