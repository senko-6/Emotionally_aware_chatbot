{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.12.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":296061796,"sourceType":"kernelVersion"}],"dockerImageVersionId":31259,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"pip install transformers datasets peft accelerate bitsandbytes","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-07T09:44:20.569990Z","iopub.execute_input":"2026-02-07T09:44:20.570541Z","iopub.status.idle":"2026-02-07T09:44:27.018349Z","shell.execute_reply.started":"2026-02-07T09:44:20.570515Z","shell.execute_reply":"2026-02-07T09:44:27.017594Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: transformers in /usr/local/lib/python3.12/dist-packages (4.57.1)\nRequirement already satisfied: datasets in /usr/local/lib/python3.12/dist-packages (4.4.2)\nRequirement already satisfied: peft in /usr/local/lib/python3.12/dist-packages (0.17.1)\nRequirement already satisfied: accelerate in /usr/local/lib/python3.12/dist-packages (1.11.0)\nCollecting bitsandbytes\n  Downloading bitsandbytes-0.49.1-py3-none-manylinux_2_24_x86_64.whl.metadata (10 kB)\nRequirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from transformers) (3.20.3)\nRequirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.36.0)\nRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2.0.2)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (26.0rc2)\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from transformers) (6.0.3)\nRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2025.11.3)\nRequirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from transformers) (2.32.5)\nRequirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.22.1)\nRequirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.6.2)\nRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.12/dist-packages (from transformers) (4.67.1)\nRequirement already satisfied: pyarrow>=21.0.0 in /usr/local/lib/python3.12/dist-packages (from datasets) (22.0.0)\nRequirement already satisfied: dill<0.4.1,>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from datasets) (0.4.0)\nRequirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from datasets) (2.2.2)\nRequirement already satisfied: httpx<1.0.0 in /usr/local/lib/python3.12/dist-packages (from datasets) (0.28.1)\nRequirement already satisfied: xxhash in /usr/local/lib/python3.12/dist-packages (from datasets) (3.6.0)\nRequirement already satisfied: multiprocess<0.70.19 in /usr/local/lib/python3.12/dist-packages (from datasets) (0.70.18)\nRequirement already satisfied: fsspec<=2025.10.0,>=2023.1.0 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (2025.10.0)\nRequirement already satisfied: psutil in /usr/local/lib/python3.12/dist-packages (from peft) (5.9.5)\nRequirement already satisfied: torch>=1.13.0 in /usr/local/lib/python3.12/dist-packages (from peft) (2.8.0+cu126)\nRequirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (3.13.3)\nRequirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx<1.0.0->datasets) (4.12.1)\nRequirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1.0.0->datasets) (2026.1.4)\nRequirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1.0.0->datasets) (1.0.9)\nRequirement already satisfied: idna in /usr/local/lib/python3.12/dist-packages (from httpx<1.0.0->datasets) (3.11)\nRequirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1.0.0->datasets) (0.16.0)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (4.15.0)\nRequirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (1.2.1rc0)\nRequirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.4.4)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2.6.3)\nRequirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft) (75.2.0)\nRequirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft) (1.13.3)\nRequirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft) (3.5)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft) (3.1.6)\nRequirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft) (12.6.77)\nRequirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft) (12.6.77)\nRequirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft) (12.6.80)\nRequirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft) (9.10.2.21)\nRequirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft) (12.6.4.1)\nRequirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft) (11.3.0.4)\nRequirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft) (10.3.7.77)\nRequirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft) (11.7.1.2)\nRequirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft) (12.5.4.2)\nRequirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft) (0.7.1)\nRequirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft) (2.27.3)\nRequirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft) (12.6.77)\nRequirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft) (12.6.85)\nRequirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft) (1.11.1.6)\nRequirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft) (3.4.0)\nRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets) (2025.2)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets) (2025.2)\nRequirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (2.6.1)\nRequirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (1.4.0)\nRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (25.4.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (1.8.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (6.7.0)\nRequirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (0.4.1)\nRequirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (1.22.0)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=1.13.0->peft) (1.3.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=1.13.0->peft) (3.0.3)\nDownloading bitsandbytes-0.49.1-py3-none-manylinux_2_24_x86_64.whl (59.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.1/59.1 MB\u001b[0m \u001b[31m34.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: bitsandbytes\nSuccessfully installed bitsandbytes-0.49.1\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"emotion_labels = [\"anger\",\"disgust\",\"fear\",\"joy\",\"sadness\",\"surprise\",\"neutral\"]\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-07T09:44:27.019958Z","iopub.execute_input":"2026-02-07T09:44:27.020397Z","iopub.status.idle":"2026-02-07T09:44:27.023861Z","shell.execute_reply.started":"2026-02-07T09:44:27.020368Z","shell.execute_reply":"2026-02-07T09:44:27.023266Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"Cheat_sheet = {\n    \"anger\": [\"calm\", \"validate\", \"de_escalate\"],\n    \"disgust\": [\"reassure\", \"support\"],\n    \"fear\": [\"reassure\", \"protect\"],\n    \"joy\": [\"celebrate\", \"share\"],\n    \"sadness\": [\"comfort\", \"validate\"],\n    \"surprise\": [\"explain\", \"react\"],\n    \"neutral\": [\"acknowledge\", \"respond\"]\n}\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-07T09:44:27.024987Z","iopub.execute_input":"2026-02-07T09:44:27.025357Z","iopub.status.idle":"2026-02-07T09:44:27.037781Z","shell.execute_reply.started":"2026-02-07T09:44:27.025326Z","shell.execute_reply":"2026-02-07T09:44:27.037169Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"import json\n\nwith open(\"/kaggle/input/notebookba7deda072/myprompts.json\", \"r\") as f:\n    myprompts = json.load(f)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-07T09:44:27.039282Z","iopub.execute_input":"2026-02-07T09:44:27.039931Z","iopub.status.idle":"2026-02-07T09:44:27.261014Z","shell.execute_reply.started":"2026-02-07T09:44:27.039894Z","shell.execute_reply":"2026-02-07T09:44:27.260480Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"import random\n\ndef myprompt_examples(emotion, n=6):\n    if emotion not in myprompts:\n        return \"\"\n\n    examples = random.sample(\n        myprompts[emotion],\n        n\n    )\n\n    myprompt_text = \"\"\n    for ex in examples:\n        myprompt_text += f\"\"\"\nUser: {ex['User']}\nAssistant: {ex['Assistant']}\n\"\"\"\n\n    return myprompt_text.strip()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-07T09:44:27.262161Z","iopub.execute_input":"2026-02-07T09:44:27.262419Z","iopub.status.idle":"2026-02-07T09:44:27.267541Z","shell.execute_reply.started":"2026-02-07T09:44:27.262398Z","shell.execute_reply":"2026-02-07T09:44:27.266993Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"from transformers import BitsAndBytesConfig\nfrom transformers import AutoModelForCausalLM, AutoTokenizer\nimport torch\nbnb_config = BitsAndBytesConfig(\n    load_in_4bit=True,\n    bnb_4bit_quant_type=\"nf4\",\n    bnb_4bit_compute_dtype=torch.float16,\n    bnb_4bit_use_double_quant=True,\n)\n\nmodel = AutoModelForCausalLM.from_pretrained(\n    \"mistralai/Mistral-7B-Instruct-v0.2\",\n    quantization_config=bnb_config,\n    device_map=\"auto\"\n)\n\ntokenizer = AutoTokenizer.from_pretrained(\"mistralai/Mistral-7B-Instruct-v0.2\")\ntokenizer.pad_token = tokenizer.eos_token\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-07T09:44:29.453534Z","iopub.execute_input":"2026-02-07T09:44:29.454099Z","iopub.status.idle":"2026-02-07T09:47:35.502416Z","shell.execute_reply.started":"2026-02-07T09:44:29.454075Z","shell.execute_reply":"2026-02-07T09:47:35.501621Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/596 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"687ec0cc71fc48d485ac6af3b041c164"}},"metadata":{}},{"name":"stderr","text":"2026-02-07 09:44:43.775450: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1770457483.973289      55 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1770457484.031274      55 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\nW0000 00:00:1770457484.484686      55 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\nW0000 00:00:1770457484.484732      55 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\nW0000 00:00:1770457484.484735      55 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\nW0000 00:00:1770457484.484737      55 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"model.safetensors.index.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e7a83c93cd50435ab4a42ea6ede1f571"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Fetching 3 files:   0%|          | 0/3 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1607332078a44592ae6bdb4151ff326e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00002-of-00003.safetensors:   0%|          | 0.00/5.00G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d93ebe8bc977405ea83417515a81cc7f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00001-of-00003.safetensors:   0%|          | 0.00/4.94G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bd5aa4c745d24e6083d3583cbce65fd0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00003-of-00003.safetensors:   0%|          | 0.00/4.54G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a64088f7606e4550804c8f667f39cf32"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2254511ef42c4a18a466fdaa71799dd1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/111 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b0791fef89c74216a3a68830192c717a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0ab206a1a2464e0bae49269dcbc41cbb"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.model:   0%|          | 0.00/493k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6f76ac66cc6249abaeabadcbcc0cca17"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9f2806cba3894d9cadfced7257f3e877"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/414 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2598d66763e742b1ab35690f378891c7"}},"metadata":{}}],"execution_count":8},{"cell_type":"code","source":"from peft import prepare_model_for_kbit_training\n\nmodel = prepare_model_for_kbit_training(model)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-07T09:47:35.503992Z","iopub.execute_input":"2026-02-07T09:47:35.504693Z","iopub.status.idle":"2026-02-07T09:47:35.947756Z","shell.execute_reply.started":"2026-02-07T09:47:35.504665Z","shell.execute_reply":"2026-02-07T09:47:35.947160Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"from peft import LoraConfig, get_peft_model\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nlora_config = LoraConfig(\n    r=16,\n    lora_alpha=32,\n    target_modules=[\"q_proj\",\"k_proj\",\"v_proj\",\"o_proj\"],\n    lora_dropout=0.05,\n    bias=\"none\",\n    task_type=\"CAUSAL_LM\"\n)\nmodel = get_peft_model(model, lora_config)\n\nfor name, param in model.named_parameters():\n    param.requires_grad = \"lora\" in name\n\ntrainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\nprint(\"Trainable parameters:\", trainable_params)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-07T09:47:35.948543Z","iopub.execute_input":"2026-02-07T09:47:35.948794Z","iopub.status.idle":"2026-02-07T09:47:36.251160Z","shell.execute_reply.started":"2026-02-07T09:47:35.948764Z","shell.execute_reply":"2026-02-07T09:47:36.250488Z"}},"outputs":[{"name":"stdout","text":"Trainable parameters: 13631488\n","output_type":"stream"}],"execution_count":10},{"cell_type":"code","source":"from datasets import Dataset\n\n\n\n\nflat_data = []\nfor req_emotion in emotion_labels:\n    for item in myprompts.get(req_emotion, []):\n\n        context = item.get(\"Context\",\"\").strip()\n\n        if context != \"\":\n            prompt_text = (\n                f\"Context: {context}\\n\"\n                f\"User: {item['User']}\\n\"\n                f\"Assistant:\"\n            )\n        else:\n            prompt_text = f\"User: {item['User']}\\nAssistant:\"\n\n        completion_text = f\" {item['Assistant']}\"\n\n        flat_data.append({\n            \"prompt\": prompt_text,\n            \"completion\": completion_text,\n            \"emotion\": req_emotion  \n        })\n\n\ndataset = Dataset.from_list(flat_data)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-07T09:49:39.343355Z","iopub.execute_input":"2026-02-07T09:49:39.343964Z","iopub.status.idle":"2026-02-07T09:49:39.557762Z","shell.execute_reply.started":"2026-02-07T09:49:39.343936Z","shell.execute_reply":"2026-02-07T09:49:39.557181Z"}},"outputs":[],"execution_count":18},{"cell_type":"code","source":"dataset = Dataset.from_list(flat_data)\nprint(f\"Total samples: {len(dataset)}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-07T09:50:12.174862Z","iopub.execute_input":"2026-02-07T09:50:12.175577Z","iopub.status.idle":"2026-02-07T09:50:12.326539Z","shell.execute_reply.started":"2026-02-07T09:50:12.175547Z","shell.execute_reply":"2026-02-07T09:50:12.325760Z"}},"outputs":[{"name":"stdout","text":"Total samples: 64591\n","output_type":"stream"}],"execution_count":20},{"cell_type":"code","source":"dataset = dataset.shuffle(seed=42)\n\ndataset = dataset.select(range(5000))\n\nprint(\"Using samples:\", len(dataset))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-07T09:50:13.429737Z","iopub.execute_input":"2026-02-07T09:50:13.430340Z","iopub.status.idle":"2026-02-07T09:50:13.457204Z","shell.execute_reply.started":"2026-02-07T09:50:13.430310Z","shell.execute_reply":"2026-02-07T09:50:13.456660Z"}},"outputs":[{"name":"stdout","text":"Using samples: 5000\n","output_type":"stream"}],"execution_count":21},{"cell_type":"code","source":"from collections import Counter\n\nlabels = [x[\"emotion\"] for x in dataset]\ncounts = Counter(labels)\n\nfor k, v in counts.items():\n    print(f\"{k:10s} : {v}\")\n\nprint(\"\\nTotal:\", sum(counts.values()))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-07T09:50:14.918947Z","iopub.execute_input":"2026-02-07T09:50:14.919318Z","iopub.status.idle":"2026-02-07T09:50:15.226878Z","shell.execute_reply.started":"2026-02-07T09:50:14.919291Z","shell.execute_reply":"2026-02-07T09:50:15.226291Z"}},"outputs":[{"name":"stdout","text":"joy        : 1140\nneutral    : 995\ndisgust    : 566\nfear       : 601\nsadness    : 663\nanger      : 780\nsurprise   : 255\n\nTotal: 5000\n","output_type":"stream"}],"execution_count":22},{"cell_type":"code","source":"\nif tokenizer.pad_token is None:\n    tokenizer.add_special_tokens({'pad_token': tokenizer.eos_token})\n\nprint(\"PAD token:\", tokenizer.pad_token)\nprint(\"PAD token ID:\", tokenizer.pad_token_id)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-07T03:53:15.963361Z","iopub.execute_input":"2026-02-07T03:53:15.963640Z","iopub.status.idle":"2026-02-07T03:53:15.968545Z","shell.execute_reply.started":"2026-02-07T03:53:15.963609Z","shell.execute_reply":"2026-02-07T03:53:15.967922Z"}},"outputs":[{"name":"stdout","text":"PAD token: </s>\nPAD token ID: 2\n","output_type":"stream"}],"execution_count":12},{"cell_type":"code","source":"def tokenize_function(examples):\n    texts = [p + c for p, c in zip(examples[\"prompt\"], examples[\"completion\"])]\n    tokenized = tokenizer(\n        texts,\n        truncation=True,\n        padding=\"max_length\",\n        max_length=256,\n    )\n \n    tokenized[\"labels\"] = tokenized[\"input_ids\"].copy()\n    return tokenized\ntokenized_dataset = dataset.map(tokenize_function, batched=True)\nprint(tokenized_dataset[0])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-07T03:53:15.969353Z","iopub.execute_input":"2026-02-07T03:53:15.969674Z","iopub.status.idle":"2026-02-07T03:53:16.983681Z","shell.execute_reply.started":"2026-02-07T03:53:15.969652Z","shell.execute_reply":"2026-02-07T03:53:16.983061Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/5000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a2163070fdb44852af700e4b6fed0acd"}},"metadata":{}},{"name":"stdout","text":"{'prompt': \"Context: Customer :Thank you! She drives an old cadillac and she drives it like a Ferrari. It's pretty grand watching her drive sometimes!\\nAgent :\\nUser: I was in awe of the driving ability of my old aunt, she's old but she still has it!\\nAssistant:\", 'completion': ' Haha... That sounds awesome. Wish I could carpool with her. I hate driving, but it sounds like she loves it.', 'input_ids': [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 14268, 28747, 16648, 714, 15896, 368, 28808, 985, 19085, 396, 1571, 13150, 425, 323, 304, 630, 19085, 378, 737, 264, 16073, 1900, 28723, 661, 28742, 28713, 3468, 3487, 6265, 559, 5009, 4662, 28808, 13, 14829, 714, 13, 730, 28747, 315, 403, 297, 264, 769, 302, 272, 7810, 5537, 302, 586, 1571, 23785, 28725, 630, 28742, 28713, 1571, 562, 630, 1309, 659, 378, 28808, 13, 7226, 11143, 28747, 382, 12980, 1101, 1725, 7258, 11923, 28723, 394, 789, 315, 829, 1253, 6474, 395, 559, 28723, 315, 7665, 7810, 28725, 562, 378, 7258, 737, 630, 13468, 378, 28723], 'attention_mask': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'labels': [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 14268, 28747, 16648, 714, 15896, 368, 28808, 985, 19085, 396, 1571, 13150, 425, 323, 304, 630, 19085, 378, 737, 264, 16073, 1900, 28723, 661, 28742, 28713, 3468, 3487, 6265, 559, 5009, 4662, 28808, 13, 14829, 714, 13, 730, 28747, 315, 403, 297, 264, 769, 302, 272, 7810, 5537, 302, 586, 1571, 23785, 28725, 630, 28742, 28713, 1571, 562, 630, 1309, 659, 378, 28808, 13, 7226, 11143, 28747, 382, 12980, 1101, 1725, 7258, 11923, 28723, 394, 789, 315, 829, 1253, 6474, 395, 559, 28723, 315, 7665, 7810, 28725, 562, 378, 7258, 737, 630, 13468, 378, 28723]}\n","output_type":"stream"}],"execution_count":13},{"cell_type":"code","source":"from transformers import Trainer, TrainingArguments, DataCollatorForSeq2Seq\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-07T03:53:16.984667Z","iopub.execute_input":"2026-02-07T03:53:16.984976Z","iopub.status.idle":"2026-02-07T03:53:18.351873Z","shell.execute_reply.started":"2026-02-07T03:53:16.984952Z","shell.execute_reply":"2026-02-07T03:53:18.351303Z"}},"outputs":[],"execution_count":14},{"cell_type":"code","source":"data_collator = DataCollatorForSeq2Seq(\n    tokenizer=tokenizer,\n    padding=True,\n    return_tensors=\"pt\"\n)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-07T03:53:18.352742Z","iopub.execute_input":"2026-02-07T03:53:18.352988Z","iopub.status.idle":"2026-02-07T03:53:18.356695Z","shell.execute_reply.started":"2026-02-07T03:53:18.352966Z","shell.execute_reply":"2026-02-07T03:53:18.356181Z"}},"outputs":[],"execution_count":15},{"cell_type":"code","source":"training_args = TrainingArguments(\n    output_dir=\"./lora_mistral\",\n    per_device_train_batch_size=1,\n    gradient_accumulation_steps=8,\n    num_train_epochs=1.5,\n    learning_rate=2e-4,\n    warmup_ratio=0.05,\n    fp16=True,\n    logging_steps=50,\n    save_steps=1000,\n    save_total_limit=2,\n    report_to=\"none\",\n    optim=\"paged_adamw_8bit\",\n    gradient_checkpointing=True\n)\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-07T03:53:18.357440Z","iopub.execute_input":"2026-02-07T03:53:18.357711Z","iopub.status.idle":"2026-02-07T03:53:18.402307Z","shell.execute_reply.started":"2026-02-07T03:53:18.357688Z","shell.execute_reply":"2026-02-07T03:53:18.401662Z"}},"outputs":[],"execution_count":16},{"cell_type":"code","source":"from transformers import Trainer\n\nclass CausalLMTrainer(Trainer):\n    def compute_loss(self, model, inputs, return_outputs=False, **kwargs):\n        labels = inputs.get(\"labels\")\n        if labels is None:\n            raise ValueError(\"Labels are missing! Make sure your dataset produces 'labels'.\")\n        inputs[\"labels\"] = labels.long()\n        \n        outputs = model(**inputs)\n        loss = getattr(outputs, \"loss\", None)\n        \n        if loss is None:\n            import torch\n            logits = outputs.logits\n            shift_logits = logits[..., :-1, :].contiguous()\n            shift_labels = inputs[\"labels\"][..., 1:].contiguous()\n            loss_fct = torch.nn.CrossEntropyLoss(ignore_index=tokenizer.pad_token_id)\n            loss = loss_fct(\n                shift_logits.view(-1, shift_logits.size(-1)),\n                shift_labels.view(-1)\n            )\n        return (loss, outputs) if return_outputs else loss\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-07T03:53:18.403193Z","iopub.execute_input":"2026-02-07T03:53:18.403486Z","iopub.status.idle":"2026-02-07T03:53:18.409558Z","shell.execute_reply.started":"2026-02-07T03:53:18.403453Z","shell.execute_reply":"2026-02-07T03:53:18.408810Z"}},"outputs":[],"execution_count":17},{"cell_type":"code","source":"trainer = CausalLMTrainer(\n    model=model,\n    args=training_args,\n    train_dataset=tokenized_dataset,\n    tokenizer=tokenizer,\n    data_collator=data_collator\n)\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-07T03:53:18.410416Z","iopub.execute_input":"2026-02-07T03:53:18.410688Z","iopub.status.idle":"2026-02-07T03:53:18.438124Z","shell.execute_reply.started":"2026-02-07T03:53:18.410666Z","shell.execute_reply":"2026-02-07T03:53:18.437490Z"}},"outputs":[{"name":"stderr","text":"/tmp/ipykernel_55/183362814.py:1: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `CausalLMTrainer.__init__`. Use `processing_class` instead.\n  trainer = CausalLMTrainer(\n","output_type":"stream"}],"execution_count":18},{"cell_type":"code","source":"trainer.train()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-07T03:53:18.438986Z","iopub.execute_input":"2026-02-07T03:53:18.439366Z","iopub.status.idle":"2026-02-07T08:10:17.308622Z","shell.execute_reply.started":"2026-02-07T03:53:18.439332Z","shell.execute_reply":"2026-02-07T08:10:17.307998Z"}},"outputs":[{"name":"stderr","text":"The tokenizer has new PAD/BOS/EOS tokens that differ from the model config and generation config. The model config and generation config were aligned accordingly, being updated with the tokenizer's values. Updated tokens: {'pad_token_id': 2}.\n`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='938' max='938' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [938/938 4:16:41, Epoch 1/2]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>50</td>\n      <td>42.449700</td>\n    </tr>\n    <tr>\n      <td>100</td>\n      <td>40.593600</td>\n    </tr>\n    <tr>\n      <td>150</td>\n      <td>40.427900</td>\n    </tr>\n    <tr>\n      <td>200</td>\n      <td>40.406000</td>\n    </tr>\n    <tr>\n      <td>250</td>\n      <td>40.565600</td>\n    </tr>\n    <tr>\n      <td>300</td>\n      <td>40.301800</td>\n    </tr>\n    <tr>\n      <td>350</td>\n      <td>40.536100</td>\n    </tr>\n    <tr>\n      <td>400</td>\n      <td>40.276800</td>\n    </tr>\n    <tr>\n      <td>450</td>\n      <td>40.441900</td>\n    </tr>\n    <tr>\n      <td>500</td>\n      <td>40.488200</td>\n    </tr>\n    <tr>\n      <td>550</td>\n      <td>40.547700</td>\n    </tr>\n    <tr>\n      <td>600</td>\n      <td>40.342900</td>\n    </tr>\n    <tr>\n      <td>650</td>\n      <td>40.239300</td>\n    </tr>\n    <tr>\n      <td>700</td>\n      <td>39.983900</td>\n    </tr>\n    <tr>\n      <td>750</td>\n      <td>39.731000</td>\n    </tr>\n    <tr>\n      <td>800</td>\n      <td>39.840200</td>\n    </tr>\n    <tr>\n      <td>850</td>\n      <td>39.689800</td>\n    </tr>\n    <tr>\n      <td>900</td>\n      <td>40.008600</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"execution_count":19,"output_type":"execute_result","data":{"text/plain":"TrainOutput(global_step=938, training_loss=40.36018472439699, metrics={'train_runtime': 15418.3479, 'train_samples_per_second': 0.486, 'train_steps_per_second': 0.061, 'total_flos': 8.21156106951721e+16, 'train_loss': 40.36018472439699, 'epoch': 1.5008})"},"metadata":{}}],"execution_count":19},{"cell_type":"code","source":"model.save_pretrained(\"/kaggle/working/emo_lora_adapter\")\ntokenizer.save_pretrained(\"/kaggle/working/emo_lora_adapter\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-07T08:10:17.309547Z","iopub.execute_input":"2026-02-07T08:10:17.309825Z","iopub.status.idle":"2026-02-07T08:10:17.917211Z","shell.execute_reply.started":"2026-02-07T08:10:17.309800Z","shell.execute_reply":"2026-02-07T08:10:17.916463Z"}},"outputs":[{"execution_count":20,"output_type":"execute_result","data":{"text/plain":"('/kaggle/working/emo_lora_adapter/tokenizer_config.json',\n '/kaggle/working/emo_lora_adapter/special_tokens_map.json',\n '/kaggle/working/emo_lora_adapter/chat_template.jinja',\n '/kaggle/working/emo_lora_adapter/tokenizer.model',\n '/kaggle/working/emo_lora_adapter/added_tokens.json',\n '/kaggle/working/emo_lora_adapter/tokenizer.json')"},"metadata":{}}],"execution_count":20},{"cell_type":"code","source":"model.eval()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-07T08:10:17.918221Z","iopub.execute_input":"2026-02-07T08:10:17.918700Z","iopub.status.idle":"2026-02-07T08:10:17.934254Z","shell.execute_reply.started":"2026-02-07T08:10:17.918675Z","shell.execute_reply":"2026-02-07T08:10:17.933587Z"}},"outputs":[{"execution_count":21,"output_type":"execute_result","data":{"text/plain":"PeftModelForCausalLM(\n  (base_model): LoraModel(\n    (model): MistralForCausalLM(\n      (model): MistralModel(\n        (embed_tokens): Embedding(32000, 4096)\n        (layers): ModuleList(\n          (0-31): 32 x MistralDecoderLayer(\n            (self_attn): MistralAttention(\n              (q_proj): lora.Linear4bit(\n                (base_layer): Linear4bit(in_features=4096, out_features=4096, bias=False)\n                (lora_dropout): ModuleDict(\n                  (default): Dropout(p=0.05, inplace=False)\n                )\n                (lora_A): ModuleDict(\n                  (default): Linear(in_features=4096, out_features=16, bias=False)\n                )\n                (lora_B): ModuleDict(\n                  (default): Linear(in_features=16, out_features=4096, bias=False)\n                )\n                (lora_embedding_A): ParameterDict()\n                (lora_embedding_B): ParameterDict()\n                (lora_magnitude_vector): ModuleDict()\n              )\n              (k_proj): lora.Linear4bit(\n                (base_layer): Linear4bit(in_features=4096, out_features=1024, bias=False)\n                (lora_dropout): ModuleDict(\n                  (default): Dropout(p=0.05, inplace=False)\n                )\n                (lora_A): ModuleDict(\n                  (default): Linear(in_features=4096, out_features=16, bias=False)\n                )\n                (lora_B): ModuleDict(\n                  (default): Linear(in_features=16, out_features=1024, bias=False)\n                )\n                (lora_embedding_A): ParameterDict()\n                (lora_embedding_B): ParameterDict()\n                (lora_magnitude_vector): ModuleDict()\n              )\n              (v_proj): lora.Linear4bit(\n                (base_layer): Linear4bit(in_features=4096, out_features=1024, bias=False)\n                (lora_dropout): ModuleDict(\n                  (default): Dropout(p=0.05, inplace=False)\n                )\n                (lora_A): ModuleDict(\n                  (default): Linear(in_features=4096, out_features=16, bias=False)\n                )\n                (lora_B): ModuleDict(\n                  (default): Linear(in_features=16, out_features=1024, bias=False)\n                )\n                (lora_embedding_A): ParameterDict()\n                (lora_embedding_B): ParameterDict()\n                (lora_magnitude_vector): ModuleDict()\n              )\n              (o_proj): lora.Linear4bit(\n                (base_layer): Linear4bit(in_features=4096, out_features=4096, bias=False)\n                (lora_dropout): ModuleDict(\n                  (default): Dropout(p=0.05, inplace=False)\n                )\n                (lora_A): ModuleDict(\n                  (default): Linear(in_features=4096, out_features=16, bias=False)\n                )\n                (lora_B): ModuleDict(\n                  (default): Linear(in_features=16, out_features=4096, bias=False)\n                )\n                (lora_embedding_A): ParameterDict()\n                (lora_embedding_B): ParameterDict()\n                (lora_magnitude_vector): ModuleDict()\n              )\n            )\n            (mlp): MistralMLP(\n              (gate_proj): Linear4bit(in_features=4096, out_features=14336, bias=False)\n              (up_proj): Linear4bit(in_features=4096, out_features=14336, bias=False)\n              (down_proj): Linear4bit(in_features=14336, out_features=4096, bias=False)\n              (act_fn): SiLUActivation()\n            )\n            (input_layernorm): MistralRMSNorm((4096,), eps=1e-05)\n            (post_attention_layernorm): MistralRMSNorm((4096,), eps=1e-05)\n          )\n        )\n        (norm): MistralRMSNorm((4096,), eps=1e-05)\n        (rotary_emb): MistralRotaryEmbedding()\n      )\n      (lm_head): Linear(in_features=4096, out_features=32000, bias=False)\n    )\n  )\n)"},"metadata":{}}],"execution_count":21},{"cell_type":"code","source":"from transformers import AutoModelForCausalLM, AutoTokenizer\nfrom peft import PeftModel\n\nbase_model = AutoModelForCausalLM.from_pretrained(\n    \"mistralai/Mistral-7B-Instruct-v0.2\",\n    torch_dtype=torch.float16,\n    device_map=\"auto\"\n)\n\nmodel = PeftModel.from_pretrained(base_model, \"./emo_lora_adapter\")\ntokenizer = AutoTokenizer.from_pretrained(\"./emo_lora_adapter\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-07T08:10:17.937491Z","iopub.execute_input":"2026-02-07T08:10:17.938005Z","iopub.status.idle":"2026-02-07T08:10:36.234833Z","shell.execute_reply.started":"2026-02-07T08:10:17.937975Z","shell.execute_reply":"2026-02-07T08:10:36.234185Z"}},"outputs":[{"name":"stderr","text":"`torch_dtype` is deprecated! Use `dtype` instead!\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d53933e4bb0c4d02b9c6b5a24a6b6b50"}},"metadata":{}},{"name":"stderr","text":"WARNING:accelerate.big_modeling:Some parameters are on the meta device because they were offloaded to the cpu.\nWARNING:accelerate.big_modeling:Some parameters are on the meta device because they were offloaded to the cpu.\n","output_type":"stream"}],"execution_count":22},{"cell_type":"code","source":"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-07T09:44:05.280755Z","iopub.execute_input":"2026-02-07T09:44:05.281018Z","iopub.status.idle":"2026-02-07T09:44:05.292488Z","shell.execute_reply.started":"2026-02-07T09:44:05.280987Z","shell.execute_reply":"2026-02-07T09:44:05.291026Z"}},"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_55/2000878549.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmyprompts\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"anger\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mNameError\u001b[0m: name 'myprompts' is not defined"],"ename":"NameError","evalue":"name 'myprompts' is not defined","output_type":"error"}],"execution_count":1},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}